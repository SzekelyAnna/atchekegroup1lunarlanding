{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LunarLanderEvtools.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIE1uBAseoNfKfgm/SuluF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SzekelyAnna/atchekegroup1lunarlanding/blob/main/LunarLanderEvtools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZFGdYjWDhDG"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_rewards = {}\n",
        "\n",
        "def generate_sample_models(number_of_models):\n",
        "    '''\n",
        "    This is function which generates sample models.\n",
        "    '''\n",
        "    for n in range(number_of_models):\n",
        "        reward_dict = {}\n",
        "        model_version_num = 'DQN' + str(n)\n",
        "        x = np.linspace(1,100,100) ## these are the timesteps\n",
        "        y = random.rand(100)\n",
        "        reward_dict = {'x': x, 'y' : y, 'comment': 'here comes the comment'}\n",
        "        all_model_rewards[model_version_num] = reward_dict\n",
        "generate_sample_models(10)"
      ],
      "metadata": {
        "id": "pOKgF-LxDy-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluations(all_model_rewards): \n",
        "    \n",
        "    '''\n",
        "    This is a function performing model evaluations. \n",
        "    \n",
        "    Input: a dict in the following format:\n",
        "    {'DQN5': {'x': array([  1.,   2.,   3.,  ....]),\n",
        "             'y': array([0.47025739, 0.5788533 , 0.72454499,...]),\n",
        "             'comment': 'comment for the model'}}\n",
        "             \n",
        "             \n",
        "             \n",
        "    The function performing the following metrics:\n",
        "    \n",
        "    Max reward:\n",
        "    \n",
        "    Jumpstart: The initial performance of an agent in a \n",
        "    target task may be improved by transfer from a source task.\n",
        "\n",
        "    Total reward: \n",
        "    '''\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    max_reward = {}\n",
        "    jumpstart = {}\n",
        "    total_reward = {}\n",
        "    asymptotic_performance = {}\n",
        "    \n",
        "    for m in all_model_rewards.keys():\n",
        "        \n",
        "        max_reward[m] = all_model_rewards[m]['y'].max()\n",
        "        \n",
        "        ####################################\n",
        "        ######### NB! Here you can define on how long section do you want to evaluate jumpstart. \n",
        "        ######### It should start from the beginning of the array. \n",
        "        ####################################\n",
        "        jumpstart[m] =  all_model_rewards[m]['y'][:10].mean() \n",
        "        \n",
        "        total_reward[m] =  all_model_rewards[m]['y'].sum()\n",
        "        \n",
        "        ####################################\n",
        "        ######### NB! Here you can define on how long section do you want to evaluate asymptotic performance. \n",
        "        ######### It end at the end of the session.\n",
        "        ####################################\n",
        "        asymptotic_performance[m] =  all_model_rewards[m]['y'][-10:].sum()\n",
        "\n",
        "        \n",
        "        \n",
        "    ## Add the metrics to the final evaluation metric \n",
        "    \n",
        "    model_evs['max_reward'] = max_reward\n",
        "    model_evs['jumpstart'] = jumpstart\n",
        "    model_evs['total_reward'] = total_reward\n",
        "    model_evs['asymptotic_performance'] = asymptotic_performance\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "model_evaluations(all_model_rewards)  \n",
        "results = pd.DataFrame(model_evs)\n",
        "results.style.highlight_max(color = 'lightgreen', axis = 0)"
      ],
      "metadata": {
        "id": "ODnN1EwXD1b6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LunarLanderEvtools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrGycjZqE3PVUMQtyVH4tj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SzekelyAnna/atchekegroup1lunarlanding/blob/main/LunarLanderEvtools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZFGdYjWDhDG"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_rewards = {}\n",
        "\n",
        "def generate_sample_models(number_of_models):\n",
        "    '''\n",
        "    This is function which generates sample models.\n",
        "    '''\n",
        "    for n in range(number_of_models):\n",
        "        reward_dict = {}\n",
        "        model_version_num = 'DQN' + str(n)\n",
        "        x = np.linspace(1,100,100) ## these are the timesteps\n",
        "        y = random.rand(100)\n",
        "        reward_dict = {'x': x, 'y' : y, 'comment': 'here comes the comment'}\n",
        "        all_model_rewards[model_version_num] = reward_dict\n",
        "generate_sample_models(10)"
      ],
      "metadata": {
        "id": "pOKgF-LxDy-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluations(all_model_rewards): \n",
        "    \n",
        "    '''\n",
        "    This is a function performing model evaluations. \n",
        "    \n",
        "    Input: a dict in the following format:\n",
        "    {'DQN5': {'x': array([  1.,   2.,   3.,  ....]),\n",
        "             'y': array([0.47025739, 0.5788533 , 0.72454499,...]),\n",
        "             'comment': 'comment for the model'}}\n",
        "             \n",
        "             \n",
        "             \n",
        "    The function performing the following metrics:\n",
        "    \n",
        "    \n",
        "    1. Max reward. \n",
        "    2. Jumpstart: The initial performance of an agent in a target task may be improved by transfer from a source task.\n",
        "    3. Asymptotic Performance: The final learned performance of an agent in the target task may be improved via transfer.\n",
        "    4. Total Reward: The total reward accumulated by an agent (i.e., the area under the learning curve) may be improved if it uses transfer, compared to learning without transfer.\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    max_reward = {}\n",
        "    jumpstart = {}\n",
        "    total_reward = {}\n",
        "    asymptotic_performance = {}\n",
        "    \n",
        "    for m in all_model_rewards.keys():\n",
        "        \n",
        "        max_reward[m] = all_model_rewards[m]['y'].max()\n",
        "        \n",
        "        ####################################\n",
        "        ######### NB! Here you can define on how long section do you want to evaluate jumpstart. \n",
        "        ######### It should start from the beginning of the array. \n",
        "        ####################################\n",
        "        jumpstart[m] =  all_model_rewards[m]['y'][:10].mean() \n",
        "        \n",
        "        total_reward[m] =  all_model_rewards[m]['y'].sum()\n",
        "        \n",
        "        ####################################\n",
        "        ######### NB! Here you can define on how long section do you want to evaluate asymptotic performance. \n",
        "        ######### It end at the end of the session.\n",
        "        ####################################\n",
        "        asymptotic_performance[m] =  all_model_rewards[m]['y'][-10:].sum()\n",
        "\n",
        "        \n",
        "        \n",
        "    ## Add the metrics to the final evaluation metric \n",
        "    \n",
        "    model_evs['max_reward'] = max_reward\n",
        "    model_evs['jumpstart'] = jumpstart\n",
        "    model_evs['total_reward'] = total_reward\n",
        "    model_evs['asymptotic_performance'] = asymptotic_performance\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "model_evaluations(all_model_rewards)  \n",
        "results = pd.DataFrame(model_evs)\n",
        "results.style.highlight_max(color = 'lightgreen', axis = 0)"
      ],
      "metadata": {
        "id": "ODnN1EwXD1b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_ratio(transfer_learner, scratch_model): \n",
        "\n",
        "    ''' Transfer Ratio: The ratio of the total reward accumulated by the transfer learner and the total reward accumulated by the non-transfer learner.'''\n",
        "\n",
        "    transfer_ratio = (transfer_learner['y']/scratch_model['y']).sum()\n",
        "    return (transfer_ratio)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def time_to_threshold(transfer_learner, scratch_model):\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    Time to Threshold: The learning time needed by the agent to achieve a pre-specified perfor- mance level may be reduced via knowledge transfer.\n",
        "\n",
        "\n",
        "    This function returns the first timestep of the transfer_learning model when it reaches the scratch\n",
        "    model's maximum value. The threshold could be changed to \n",
        "        - any fixed number\n",
        "        - ratio of the scratch model's maximum reward\n",
        "        - the average of the final performance (averaged over the last n timesteps) of the scratch model. \n",
        "    '''\n",
        "    \n",
        "    threshold = scratch_model['y'].max()\n",
        "    threshold_index = np.where(transfer_learner['y'] >= threshold)[0][0]\n",
        "    \n",
        "    \n",
        "    return 'Transfer learner\\'s performance reaches the threashold (scratch model\\'s max performance) at timestap {}. Threshold is {}'.format(threshold_index, threshold)\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "OS3lNNLXQc2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}